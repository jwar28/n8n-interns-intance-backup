{
  "updatedAt": "2026-02-06T17:56:37.738Z",
  "createdAt": "2026-01-21T21:47:38.125Z",
  "id": "hck4UjK0ZB1_4q0VifmuE",
  "name": "My workflow",
  "active": false,
  "isArchived": true,
  "nodes": [
    {
      "parameters": {
        "options": {
          "responseMode": "lastNode"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.4,
      "position": [
        16,
        0
      ],
      "id": "f4379710-a4e6-4d8d-8b9e-558bfdbf2dfe",
      "name": "When chat message received",
      "webhookId": "0a3eb3cb-cbb7-446d-92c6-cb0affa6d6a6"
    },
    {
      "parameters": {
        "code": {
          "execute": {
            "code": "// Gemini + Simple Memory (BufferWindowMemory) — versión simplificada\n\nconst input =\n\t(items[0].json?.chatInput ??\n\t\titems[0].json?.message?.text ??\n\t\titems[0].json?.text ??\n\t\titems[0].json?.input ??\n\t\titems[0].json?.query ??\n\t\t\"\").toString().trim();\n\nif (!input) return [{ json: { text: \"No recibí texto del chat.\" } }];\n\n// Modelo\nconst llmConn = await this.getInputConnectionData(\"ai_languageModel\", 0);\nconst llm = Array.isArray(llmConn) ? llmConn[0] : llmConn;\n\n// Memoria (opcional)\nlet memory = null;\ntry {\n\tconst memConn = await this.getInputConnectionData(\"ai_memory\", 0);\n\tmemory = Array.isArray(memConn) ? memConn[0] : memConn;\n} catch {}\n\n// Historial\nlet historyText = \"\";\nif (memory?.loadMemoryVariables) {\n\tconst vars = await memory.loadMemoryVariables({});\n\tconst history = vars?.[memory?.memoryKey ?? \"history\"] ?? [];\n\n\tif (Array.isArray(history)) {\n\t\thistoryText = history\n\t\t\t.map((m) => {\n\t\t\t\t// Formato típico en n8n: m.id incluye \"HumanMessage\"/\"AIMessage\" y contenido en m.kwargs.content\n\t\t\t\tconst type = Array.isArray(m?.id) ? m.id[m.id.length - 1] : \"\";\n\t\t\t\tconst role =\n\t\t\t\t\ttype === \"HumanMessage\" ? \"Usuario\" :\n\t\t\t\t\ttype === \"AIMessage\" ? \"Asistente\" :\n\t\t\t\t\t\"Mensaje\";\n\t\t\t\tconst content = (m?.kwargs?.content ?? m?.content ?? \"\").toString();\n\t\t\t\treturn content ? `${role}: ${content}` : \"\";\n\t\t\t})\n\t\t\t.filter(Boolean)\n\t\t\t.join(\"\\n\");\n\t} else if (typeof history === \"string\") {\n\t\thistoryText = history;\n\t}\n}\n\n// Prompt + respuesta\nconst system =\n`Eres un asistente general. Ayuda con cualquier pregunta.\nResponde de forma breve, clara y directa.\nSi la pregunta es ambigua, pide una aclaración mínima.\nUsa el historial solo si es relevante. No lo repitas ni lo menciones.\n\nHistorial del chat:\n${historyText || \"(vacío)\"}`;\n\nconst res = await llm.invoke([\n\t[\"system\", system],\n\t[\"human\", input],\n]);\n\nconst text = (res?.content ?? res ?? \"\").toString();\n\n// Guardar en memoria\nif (memory?.saveContext) {\n\tawait memory.saveContext({ input }, { output: text });\n}\n\nreturn [{ json: { text } }];"
          }
        },
        "inputs": {
          "input": [
            {
              "type": "main"
            },
            {
              "type": "ai_languageModel"
            },
            {
              "type": "ai_tool"
            },
            {
              "type": "ai_memory"
            }
          ]
        },
        "outputs": {
          "output": [
            {
              "type": "main"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.code",
      "typeVersion": 1,
      "position": [
        240,
        0
      ],
      "id": "43840594-b7aa-47a3-8acb-4b501dca2f65",
      "name": "LangChain Code"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        208,
        224
      ],
      "id": "e4fc6801-ed38-4d38-bd78-e32da9dd8c31",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "iMjPY9IRwa2fZuTA",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        384,
        224
      ],
      "id": "822b2860-7734-4f50-867d-713d82188bd0",
      "name": "Simple Memory"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3.1,
      "position": [
        640,
        0
      ],
      "id": "32d249d5-12a9-4ad4-ba22-762e1fabf161",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.9,
      "position": [
        640,
        240
      ],
      "id": "e2ed9955-fba6-48c6-a9be-acfd8e8027fe",
      "name": "Basic LLM Chain"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainRetrievalQa",
      "typeVersion": 1.7,
      "position": [
        1008,
        0
      ],
      "id": "73f5e7d4-2588-4bd3-a17e-33bd2973b460",
      "name": "Question and Answer Chain"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.sentimentAnalysis",
      "typeVersion": 1.1,
      "position": [
        1008,
        224
      ],
      "id": "a7110244-296f-41e4-85ec-f02a9c3b7ca7",
      "name": "Sentiment Analysis"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainSummarization",
      "typeVersion": 2.1,
      "position": [
        1376,
        0
      ],
      "id": "b6ad6086-6a59-422f-87be-f77be6c4f666",
      "name": "Summarization Chain"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.textClassifier",
      "typeVersion": 1.1,
      "position": [
        1376,
        240
      ],
      "id": "d10a35f4-42dc-42c5-b05b-43029795d8ed",
      "name": "Text Classifier"
    }
  ],
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "LangChain Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "LangChain Code",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "LangChain Code",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent": {
      "main": [
        []
      ]
    },
    "Summarization Chain": {
      "main": [
        []
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "availableInMCP": false
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {},
  "versionId": "658de5c6-7f86-49ac-8dfe-07dd93cbf5e8",
  "activeVersionId": null,
  "triggerCount": 0,
  "shared": [
    {
      "updatedAt": "2026-01-21T21:47:38.125Z",
      "createdAt": "2026-01-21T21:47:38.125Z",
      "role": "workflow:owner",
      "workflowId": "hck4UjK0ZB1_4q0VifmuE",
      "projectId": "bmvDuE1r6YNTedFD"
    }
  ],
  "activeVersion": null,
  "tags": []
}